{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0553ddbb",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f96f6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # --- Develop\n",
    "    \"is_test\": False,\n",
    "    \"test_sample_per_label\": 2,\n",
    "    \n",
    "    # --- Training data\n",
    "    \"train_data\": \"/Users/dauduchieu/Desktop/iSE_CBM_CIN/data/test-20k.csv\",\n",
    "    \"text_col\": \"abstract_text\",\n",
    "    \"label_col\": \"target\",\n",
    "    \"label_map\": {\n",
    "        \"BACKGROUND\": \"background\",\n",
    "        \"OBJECTIVE\": \"objective\",\n",
    "        \"METHODS\": \"methods\",\n",
    "        \"RESULTS\": \"results\",\n",
    "        \"CONCLUSIONS\": \"conclusions\"\n",
    "    },\n",
    "    \n",
    "    # Concept generation\n",
    "    \"concepts\": {\n",
    "        \"keyword_concepts\": {\n",
    "            \"0\": [\"aim\", \"develop\", \"cancer\", \"common\"],\n",
    "            \"1\": [\"aim\", \"develop\", \"cancer\", \"common\"],\n",
    "            \"2\": [\"aim\", \"develop\", \"cancer\", \"common\"]\n",
    "        },\n",
    "        \"abstract_concepts\": {\n",
    "            \"a\": {\n",
    "                \"Adverse\": [\"aim\", \"develop\"], \n",
    "                \"Treatment\": [\"turn\", \"cold\"], \n",
    "                \"Intense\": [\"hate\"]\n",
    "            },\n",
    "            \"b\": {\n",
    "                \"Reactions\": [\"aim\", \"develop\"], \n",
    "                \"Failure\": [\"turn\", \"cold\"], \n",
    "                \"Dislike\": [\"hate\"]\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ebcde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(CONFIG[\"train_data\"])\n",
    "train_df = train_df[[CONFIG[\"text_col\"], CONFIG[\"label_col\"]]]\n",
    "train_df = train_df.rename(columns={CONFIG[\"text_col\"]: \"text\", CONFIG[\"label_col\"]: \"label\"})\n",
    "\n",
    "train_df[\"label\"] = train_df[\"label\"].map(CONFIG[\"label_map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2fcffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>Gilead Sciences .</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>Tuberculosis regimens that are shorter and sim...</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>To verify the clinical efficacy of shu-stream ...</td>\n",
       "      <td>objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>Tunneling significantly reduced average extent...</td>\n",
       "      <td>results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Poor management of chronic medical treatments ...</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text       label\n",
       "1730                                  Gilead Sciences .  background\n",
       "1611  Tuberculosis regimens that are shorter and sim...  background\n",
       "2902  To verify the clinical efficacy of shu-stream ...   objective\n",
       "565   Tunneling significantly reduced average extent...     results\n",
       "1254  Poor management of chronic medical treatments ...  background"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607874e",
   "metadata": {},
   "source": [
    "# Concepts Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec8a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2abab430",
   "metadata": {},
   "source": [
    "# Concepts Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee86bbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dauduchieu/Desktop/iSE_CBM_CIN/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "class NLIModel:\n",
    "    def __init__(self, model_name_or_path: str = 'bert-base-uncased', num_labels: int = 2):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Loading model from: {model_name_or_path}\")\n",
    "\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=num_labels)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading with AutoClasses, trying Bert-specific classes directly. Error: {e}\")\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(model_name_or_path)\n",
    "            self.model = BertForSequenceClassification.from_pretrained(model_name_or_path, num_labels=num_labels)\n",
    "            \n",
    "        self.model.to(self.device)\n",
    "        print(f\"Model loaded successfully on: {self.device}\")\n",
    "\n",
    "    def train(self, train_loader: DataLoader, val_loader: DataLoader = None, epochs: int = 1, lr: float = 2e-5):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            loop = tqdm(train_loader, leave=True)\n",
    "            total_loss = 0.0\n",
    "            for batch in loop:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                loop.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch+1} - Average loss: {avg_loss:.4f}\")\n",
    "            if val_loader is not None:\n",
    "                self.evaluate(val_loader)\n",
    "\n",
    "    def evaluate(self, val_loader: DataLoader):\n",
    "        self.model.eval()\n",
    "        preds, labels_list = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "                preds.extend(predictions.cpu().numpy())\n",
    "                labels_list.extend(labels.cpu().numpy())\n",
    "        acc = accuracy_score(labels_list, preds)\n",
    "        print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "        return acc\n",
    "\n",
    "    def score(self, text: str, concept: str) -> float:\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(\n",
    "                text,\n",
    "                concept,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=256\n",
    "            ).to(self.device)\n",
    "            outputs = self.model(**inputs)\n",
    "            probs = torch.softmax(outputs.logits, dim=1)\n",
    "            score = probs[0][1].item()\n",
    "        return score\n",
    "\n",
    "    def batch_score(self, text: str, concepts: list[str]) -> list[float]:\n",
    "        self.model.eval()\n",
    "        num_concepts = len(concepts)\n",
    "        if num_concepts == 0:\n",
    "            return []\n",
    "        \n",
    "        text_inputs = [text] * num_concepts\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(\n",
    "                text_inputs,\n",
    "                concepts,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=256\n",
    "            ).to(self.device)\n",
    "\n",
    "            outputs = self.model(**inputs) # [Batch_size, Num_Labels]\n",
    "            probs = torch.softmax(outputs.logits, dim=1)\n",
    "            \n",
    "            # score label 1\n",
    "            scores = probs[:, 1].cpu().tolist() # [Batch_size]\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def save_model(self, output_dir: str):\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        self.model.save_pretrained(output_dir)\n",
    "        self.tokenizer.save_pretrained(output_dir)\n",
    "        print(f\"Model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca038b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on: cpu\n"
     ]
    }
   ],
   "source": [
    "nli_model = NLIModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f32b03f",
   "metadata": {},
   "source": [
    "# Concepts Interpretable Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c647ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aim', 'develop', 'cancer', 'common', 'aim', 'develop', 'cancer', 'common', 'aim', 'develop', 'cancer', 'common']\n",
      "['Adverse', 'Treatment', 'Intense', 'Reactions', 'Failure', 'Dislike']\n",
      "['background', 'objective', 'methods', 'results', 'conclusions']\n"
     ]
    }
   ],
   "source": [
    "keyword_concept_list = []\n",
    "abstract_concept_list = []\n",
    "label_concept_list = []\n",
    "\n",
    "c_kw_c = CONFIG[\"concepts\"][\"keyword_concepts\"]\n",
    "c_ab_c = CONFIG[\"concepts\"][\"abstract_concepts\"]\n",
    "\n",
    "for l in c_kw_c.values():\n",
    "    keyword_concept_list.extend(l)\n",
    "\n",
    "for l in c_ab_c.keys():\n",
    "    abstract_concept_list.extend(list(c_ab_c[l].keys()))\n",
    "\n",
    "label_concept_list = list(CONFIG[\"label_map\"].values())\n",
    "\n",
    "print(keyword_concept_list)\n",
    "print(abstract_concept_list)\n",
    "print(label_concept_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f3aa233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ea4959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CINDataset(Dataset):\n",
    "    def __init__(self, texts:list[str], labels:list[int]):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"text\": self.texts[idx],\n",
    "            \"label\": self.labels[idx],\n",
    "            \"idx\": idx\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f3bba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIN(nn.Module):\n",
    "    def __init__(self, keyword_concepts:list[str], abstract_concepts:list[str], label_concepts:list[str]):\n",
    "        super(CIN, self).__init__()\n",
    "        self.nli_model = nli_model\n",
    "        self.keyword_concepts = keyword_concepts\n",
    "        self.abstract_concepts = abstract_concepts\n",
    "        self.label_concepts = label_concepts\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "    def forward(self, texts:list[str]) -> torch.Tensor:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f007302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
