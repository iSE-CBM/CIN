{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5393aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # --- Develop\n",
    "    \"is_test\": False,\n",
    "    \"test_sample_per_label\": 2,\n",
    "    \n",
    "    # --- Training data\n",
    "    \"train_data\": \"D:\\\\CIN\\\\data\\\\train-20k.csv\",\n",
    "    \"test_data\": \"D:\\\\CIN\\\\data\\\\test-20k.csv\",\n",
    "    \"text_col\": \"abstract_text\",\n",
    "    \"label_col\": \"target\",\n",
    "    \"label_map\": {\n",
    "        \"BACKGROUND\": \"background\",\n",
    "        \"OBJECTIVE\": \"objective\",\n",
    "        \"METHODS\": \"methods\",\n",
    "        \"RESULTS\": \"results\",\n",
    "        \"CONCLUSIONS\": \"conclusions\"\n",
    "    },\n",
    "\n",
    "    # api_key\n",
    "    \"api_key\": 'AIzaSyCyfX-EyLO1SNTtHoqtYVUOnjk_hBwfuUs',\n",
    "\n",
    "    \"class_descriptions\": [\n",
    "        \"Provides context or background information that sets the stage for the research. It explains what is already known and why the study is needed.\",\n",
    "    \"Summarizes the overall findings or implications of the study. This section highlights what was learned and its significance.\",\n",
    "    \"Describes how the study was conducted, including details on the design, procedures, participants, and analysis methods used.\",\n",
    "    \"States the purpose or aim of the study, often outlining the hypothesis or specific research question being addressed.\",\n",
    "    \"Presents the outcomes or findings of the research, typically including statistical data, observations, and key results.\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e692c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d1db13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(CONFIG[\"train_data\"])\n",
    "train_df = train_df[[CONFIG[\"text_col\"], CONFIG[\"label_col\"]]]\n",
    "train_df = train_df.rename(columns={CONFIG[\"text_col\"]: \"text\", CONFIG[\"label_col\"]: \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e07d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label\"] = train_df[\"label\"].map(CONFIG[\"label_map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3ec9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(CONFIG[\"test_data\"])\n",
    "test_df = test_df[[CONFIG[\"text_col\"], CONFIG[\"label_col\"]]]\n",
    "test_df = test_df.rename(columns={CONFIG[\"text_col\"]: \"text\", CONFIG[\"label_col\"]: \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "744d0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"label\"] = test_df[\"label\"].map(CONFIG[\"label_map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be6aaeb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8705</th>\n",
       "      <td>This integrated vector management program can ...</td>\n",
       "      <td>conclusions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>Headache frequency was significantly reduced w...</td>\n",
       "      <td>results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11531</th>\n",
       "      <td>The primary outcome was a composite of wound i...</td>\n",
       "      <td>methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7151</th>\n",
       "      <td>Seventy patients , aged 18 to 45years with a p...</td>\n",
       "      <td>methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>The decreases in the mean number of the anti-g...</td>\n",
       "      <td>results</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text        label\n",
       "8705   This integrated vector management program can ...  conclusions\n",
       "9881   Headache frequency was significantly reduced w...      results\n",
       "11531  The primary outcome was a composite of wound i...      methods\n",
       "7151   Seventy patients , aged 18 to 45years with a p...      methods\n",
       "2734   The decreases in the mean number of the anti-g...      results"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1e658",
   "metadata": {},
   "source": [
    "# Concepts Generation:\n",
    "input: data\n",
    "output: \n",
    "{\n",
    "    \"keyword_concepts\": dict[str:list[str]],\n",
    "    \"abstract_concepts\": dict[str:list[str]]\n",
    "}\n",
    "\n",
    "VD:\n",
    "keyword_concepts = {\n",
    "    \"0\": [\"aim\", \"develop\", \"cancer\", \"common\"],\n",
    "    \"1\": [\"aim\", \"develop\", \"cancer\", \"common\"],\n",
    "    \"2\": [\"aim\", \"develop\", \"cancer\", \"common\"]\n",
    "}\n",
    "\n",
    "abstract_concepts = {\n",
    "    \"0\": {\n",
    "        \"Adverse Reactions\": [\"aim\", \"develop\"], \n",
    "        \"Treatment Failure\": [\"turn\", \"cold\"], \n",
    "        \"Intense Dislike\": [\"hate\"]\n",
    "    },\n",
    "    \"1\": {\n",
    "        \"Adverse Reactions\": [\"aim\", \"develop\"], \n",
    "        \"Treatment Failure\": [\"turn\", \"cold\"], \n",
    "        \"Intense Dislike\": [\"hate\"]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58272814",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column = \"text\"\n",
    "label_column = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7377e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.genai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6877f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key = CONFIG[\"api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24c5f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "import time\n",
    "\n",
    "class GeminiCaller:\n",
    "  def __init__(self, keys:list[str], model:str, rpm:int=1):\n",
    "    self.clients = [genai.Client(api_key=key) for key in keys]\n",
    "    self.model = model\n",
    "    self.rpm = rpm * len(self.clients)\n",
    "    self.cidx = 0\n",
    "    self.last_call_time = 0\n",
    "\n",
    "  def _rate_limit_wait(self):\n",
    "    time_since_last_call = time.time() - self.last_call_time\n",
    "    if time_since_last_call < 60 / self.rpm:\n",
    "      time.sleep(60 / self.rpm - time_since_last_call)\n",
    "\n",
    "  def _get_client_and_update_index(self):\n",
    "    client = self.clients[self.cidx]\n",
    "    self.cidx = (self.cidx + 1) % len(self.clients)\n",
    "    self.last_call_time = time.time()\n",
    "    return client\n",
    "\n",
    "  def call(self, contents:list, output_struct={ \"type\": \"string\" }):\n",
    "    self._rate_limit_wait()\n",
    "    client = self._get_client_and_update_index()\n",
    "\n",
    "    try:\n",
    "      response = client.models.generate_content(\n",
    "        model=self.model,\n",
    "        contents=contents,\n",
    "        config={\n",
    "          'response_mime_type': 'application/json',\n",
    "          'response_schema': output_struct\n",
    "        }\n",
    "      )\n",
    "      return response.parsed, None\n",
    "    except Exception as e:\n",
    "      print(f\"Error calling Gemini API: {e}\")\n",
    "      return None, e\n",
    "\n",
    "  def call_web_search(self, contents:list):\n",
    "    self._rate_limit_wait()\n",
    "    client = self._get_client_and_update_index()\n",
    "\n",
    "    search_config = {\n",
    "      'tools': [{'google_search': {}}]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "      response = client.models.generate_content(\n",
    "        model=self.model,\n",
    "        contents=contents,\n",
    "        config=search_config\n",
    "      )\n",
    "      return response.text, None\n",
    "    except Exception as e:\n",
    "      print(f\"Error calling Gemini API with web search: {e}\")\n",
    "      return None, e\n",
    "\n",
    "  def calculate_token(self, contents:list=[]):\n",
    "    client = self.clients[self.cidx]\n",
    "    # self.cidx = (self.cidx + 1) % len(self.clients)\n",
    "    # self.last_call_time = time.time()\n",
    "    token_resp = client.models.count_tokens(\n",
    "        model=self.model,\n",
    "        contents=contents\n",
    "    )\n",
    "    return token_resp.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0e9ef089",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = GeminiCaller(\n",
    "    keys=[\n",
    "        \"AIzaSyCyfX-EyLO1SNTtHoqtYVUOnjk_hBwfuUs\"\n",
    "    ],\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    rpm=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6eb4cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0212f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93e0d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_custom_candidates(\n",
    "    text: str,\n",
    "    use_pos: bool = True,\n",
    "    pos_list: Optional[List[str]] = None\n",
    ") -> List[str]:\n",
    "    doc = nlp(text)\n",
    "    candidates: List[str] = []\n",
    "\n",
    "    if use_pos:\n",
    "        if pos_list is None:\n",
    "            pos_list = [\"NOUN\", \"PROPN\", \"ADJ\"]\n",
    "        for token in doc:\n",
    "            if token.pos_ in pos_list and not token.is_stop and token.is_alpha:\n",
    "                candidates.append(token.lemma_.lower())\n",
    "                \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68d40998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_to_candidate_strings(\n",
    "    texts: List[str],\n",
    "    use_pos: bool = True,\n",
    "    pos_list: Optional[List[str]] = None\n",
    ") -> List[str]:\n",
    "    outs: List[str] = []\n",
    "    for t in texts:\n",
    "        cands = extract_custom_candidates(\n",
    "            str(t), use_pos=use_pos, pos_list=pos_list\n",
    "        )\n",
    "        outs.append(\" \".join(cands))\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04233f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_concepts_per_label_with_df_ilf(\n",
    "    df: pd.DataFrame,\n",
    "    text_col: str,\n",
    "    label_col: str,\n",
    "    use_pos: bool = True,\n",
    "    pos_list: Optional[List[str]] = None,\n",
    "    threshold: float = 0.02,     \n",
    "    smooth: bool = True,\n",
    "    min_df_doc: int = 1          \n",
    ") -> Tuple[Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Trả về:\n",
    "      - ranked_terms_per_label: dict(label -> list terms sắp xếp theo DF–ILF giảm dần)\n",
    "      - term_df_global: dict(term -> DF toàn cục)\n",
    "    \"\"\"\n",
    "    texts = df[text_col].astype(str).tolist()\n",
    "    labels = df[label_col].tolist()\n",
    "    uniq_labels = list(pd.Series(labels).unique())\n",
    "    num_labels = len(uniq_labels)\n",
    "\n",
    "    # Candidate set cho từng văn bản\n",
    "    cand_sets: List[set] = []\n",
    "    for t in texts:\n",
    "        cands = extract_custom_candidates(\n",
    "            t, use_pos=use_pos, pos_list=pos_list\n",
    "        )\n",
    "        cand_sets.append(set(cands))\n",
    "\n",
    "    # DF theo nhãn & DF toàn cục\n",
    "    doc_freq_by_label: Dict = defaultdict(lambda: defaultdict(int))\n",
    "    label_counts: Dict = defaultdict(int)\n",
    "    term_df_global: Dict = defaultdict(int)\n",
    "\n",
    "    for s, lab in zip(cand_sets, labels):\n",
    "        label_counts[lab] += 1\n",
    "        for term in s:\n",
    "            doc_freq_by_label[lab][term] += 1\n",
    "            term_df_global[term] += 1\n",
    "\n",
    "    # Lọc theo min_df_doc\n",
    "    if min_df_doc > 1:\n",
    "        valid_terms = {t for t, gdf in term_df_global.items() if gdf >= min_df_doc}\n",
    "    else:\n",
    "        valid_terms = set(term_df_global.keys())\n",
    "\n",
    "    # ILF theo nhãn (đếm số nhãn mà term vượt threshold tần suất)\n",
    "    ilf_scores: Dict[str, float] = defaultdict(float)\n",
    "    for term in valid_terms:\n",
    "        label_occ = 0\n",
    "        for lab in uniq_labels:\n",
    "            n_lab = max(1, label_counts[lab])\n",
    "            freq_lab = doc_freq_by_label[lab][term] / n_lab\n",
    "            if freq_lab > threshold:\n",
    "                label_occ += 1\n",
    "        ilf_scores[term] = np.log(num_labels / label_occ) if label_occ > 0 else 0.0\n",
    "\n",
    "    # Điểm DF–ILF cho từng nhãn và xếp hạng\n",
    "    ranked_terms_per_label: Dict = {}\n",
    "    for lab in uniq_labels:\n",
    "        n_lab = max(1, label_counts[lab])\n",
    "        keyword_scores: Dict[str, float] = {}\n",
    "        for term, df_val in doc_freq_by_label[lab].items():\n",
    "            if term not in valid_terms:\n",
    "                continue\n",
    "            normalized_df = df_val / n_lab\n",
    "            df_score = np.log(1 + normalized_df) if smooth else normalized_df\n",
    "            keyword_scores[term] = df_score * ilf_scores[term]\n",
    "        sorted_terms = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        ranked_terms_per_label[lab] = [t for t, _ in sorted_terms]\n",
    "\n",
    "    return ranked_terms_per_label, term_df_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "197f2635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_proxy(\n",
    "    X_full,\n",
    "    y: np.ndarray,\n",
    "    vectorizer: TfidfVectorizer,\n",
    "    feature_terms: List[str],\n",
    "    train_idx: np.ndarray,\n",
    "    valid_idx: np.ndarray,\n",
    "    metric: str = \"macro_f1\",\n",
    "):\n",
    "    \"\"\"\n",
    "    - X_full: ma trận TF–IDF của candidate strings trên vocab đầy đủ\n",
    "    - feature_terms: các term được chọn (union từ mọi nhãn)\n",
    "    - Lấy các cột tương ứng với feature_terms và train Logistic Regression\n",
    "    \"\"\"\n",
    "    vocab = vectorizer.vocabulary_\n",
    "    chosen_cols = [vocab[t] for t in feature_terms if t in vocab]\n",
    "    if len(chosen_cols) == 0:\n",
    "        return None, 0.0\n",
    "\n",
    "    X = X_full[:, chosen_cols]\n",
    "    X_tr, y_tr = X[train_idx], y[train_idx]\n",
    "    X_va, y_va = X[valid_idx], y[valid_idx]\n",
    "\n",
    "    clf = LogisticRegression(max_iter=500)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    y_pred = clf.predict(X_va)\n",
    "\n",
    "    if metric == \"accuracy\":\n",
    "        score = accuracy_score(y_va, y_pred)\n",
    "    else:\n",
    "        score = f1_score(y_va, y_pred, average=\"macro\")\n",
    "    return clf, float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa531f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_select_concepts_with_proxy_df_ilf(\n",
    "    df: pd.DataFrame,\n",
    "    text_col: str,\n",
    "    label_col: str,\n",
    "    k: int = 5,\n",
    "    max_iters: int = 10,\n",
    "    relative_min_improve: float = 0.10,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    "    # extractor options\n",
    "    use_pos: bool = True,\n",
    "    pos_list: Optional[List[str]] = None,\n",
    "    # DF–ILF options\n",
    "    threshold: float = 0.02,\n",
    "    smooth: bool = True,\n",
    "    min_df_doc: int = 1,\n",
    "    # proxy options\n",
    "    tfidf_min_df: int = 1,\n",
    "    metric: str = \"macro_f1\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Trả về:\n",
    "      - layer_1_keywords: defaultdict(list)  # label -> list concept đã chọn (best snapshot)\n",
    "      - history: list[dict] (iter, n_union_features, score, rel_gain, added_terms)\n",
    "    \"\"\"\n",
    "    # 1) Xếp hạng concept theo DF–ILF\n",
    "    ranked_per_label, _ = rank_concepts_per_label_with_df_ilf(\n",
    "        df=df, text_col=text_col, label_col=label_col,\n",
    "        use_pos=use_pos, pos_list=pos_list,\n",
    "        threshold=threshold, smooth=smooth, min_df_doc=min_df_doc\n",
    "    )\n",
    "\n",
    "    # 2) Chuẩn bị TF–IDF để feed proxy\n",
    "    texts = df[text_col].astype(str).tolist()\n",
    "    labels_arr = df[label_col].values\n",
    "    cand_strings = preprocess_to_candidate_strings(\n",
    "        texts, use_pos=use_pos, pos_list=pos_list\n",
    "    )\n",
    "    vectorizer = TfidfVectorizer(min_df=tfidf_min_df, token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "    X_full = vectorizer.fit_transform(cand_strings)\n",
    "\n",
    "    # 3) Chia train/valid\n",
    "    idx = np.arange(len(df))\n",
    "    train_idx, valid_idx = train_test_split(\n",
    "        idx, test_size=test_size, random_state=random_state, stratify=labels_arr\n",
    "    )\n",
    "\n",
    "    uniq_labels = list(pd.Series(labels_arr).unique())\n",
    "    selected_per_label: Dict = defaultdict(list)\n",
    "    cursor_per_label = {lab: 0 for lab in uniq_labels}\n",
    "\n",
    "    def union_features(dct: Dict) -> List[str]:\n",
    "        seen = set()\n",
    "        ordered: List[str] = []\n",
    "        for lab in uniq_labels:\n",
    "            for t in dct[lab]:\n",
    "                if t not in seen:\n",
    "                    seen.add(t)\n",
    "                    ordered.append(t)\n",
    "        return ordered\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_snapshot: Optional[Dict] = None\n",
    "    history: List[Dict] = []\n",
    "\n",
    "    prev_score: Optional[float] = None\n",
    "\n",
    "    for it in range(1, max_iters + 1):\n",
    "        # Thêm k concept/label từ ranking DF–ILF\n",
    "        added_this_round: Dict = defaultdict(list)\n",
    "        for lab in uniq_labels:\n",
    "            ranked = ranked_per_label.get(lab, [])\n",
    "            start = cursor_per_label[lab]\n",
    "            end = min(start + k, len(ranked))\n",
    "            new_terms = ranked[start:end]\n",
    "            cursor_per_label[lab] = end\n",
    "\n",
    "            new_terms = [t for t in new_terms if t not in selected_per_label[lab]]\n",
    "            selected_per_label[lab].extend(new_terms)\n",
    "            added_this_round[lab] = new_terms\n",
    "\n",
    "        union_terms = union_features(selected_per_label)\n",
    "\n",
    "        # Train & Eval proxy\n",
    "        _, score = train_eval_proxy(\n",
    "            X_full, labels_arr, vectorizer, union_terms,\n",
    "            train_idx, valid_idx, metric=metric\n",
    "        )\n",
    "\n",
    "        # Tính cải thiện tương đối\n",
    "        if prev_score is None:\n",
    "            rel_gain = 0.0\n",
    "            improved = True  # vòng đầu tiên luôn chấp nhận\n",
    "        else:\n",
    "            denom = max(abs(prev_score), 1e-8)\n",
    "            rel_gain = (score - prev_score) / denom\n",
    "            improved = (rel_gain > relative_min_improve)\n",
    "\n",
    "        history.append({\n",
    "            \"iter\": it,\n",
    "            \"n_union_features\": len(union_terms),\n",
    "            \"score\": score,\n",
    "            \"rel_gain\": rel_gain,\n",
    "            \"added_terms\": {lab: added_this_round[lab] for lab in uniq_labels},\n",
    "        })\n",
    "\n",
    "        # Cập nhật best & quyết định dừng\n",
    "        if improved:\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_snapshot = {lab: list(terms) for lab, terms in selected_per_label.items()}\n",
    "            prev_score = score\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        # Hết term cho mọi nhãn thì dừng\n",
    "        if all(cursor_per_label[lab] >= len(ranked_per_label.get(lab, [])) for lab in uniq_labels):\n",
    "            break\n",
    "\n",
    "    # 5) Trả layer_1_keywords (defaultdict(list))\n",
    "    layer_1_keywords: Dict = defaultdict(list)\n",
    "    if best_snapshot:\n",
    "        for lab in uniq_labels:\n",
    "            layer_1_keywords[lab] = best_snapshot.get(lab, [])\n",
    "    else:\n",
    "        for lab in uniq_labels:\n",
    "            layer_1_keywords[lab] = []\n",
    "\n",
    "    return layer_1_keywords, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf187cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_keywords, hist = incremental_select_concepts_with_proxy_df_ilf(\n",
    "    df=train_df,\n",
    "    text_col=text_column,\n",
    "    label_col=label_column,\n",
    "    k=5,\n",
    "    max_iters=10,\n",
    "    relative_min_improve=0.05,        \n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    use_pos=True, pos_list=[\"NOUN\", \"VERB\", \"ADJ\"],\n",
    "    threshold=0.02, smooth=True, min_df_doc=5,\n",
    "    tfidf_min_df=1,\n",
    "    metric=\"macro_f1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12c040f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_layer(layer_1_keywords, label_names=None, width=3):\n",
    "    \"\"\"\n",
    "    layer_1_keywords: defaultdict(list)  # {label: [concepts]}\n",
    "    label_names: dict optional, ví dụ {0: \"Oncology\", 1: \"GI\", ...}\n",
    "    width: số cột/line khi in\n",
    "    \"\"\"\n",
    "    for lab in sorted(layer_1_keywords.keys()):\n",
    "        name = f\"{lab}\" if label_names is None else f\"{lab} - {label_names.get(lab, lab)}\"\n",
    "        concepts = layer_1_keywords[lab]\n",
    "        print(f\"\\n=== Label {name} ({len(concepts)} concepts) ===\")\n",
    "        for i, term in enumerate(concepts, start=1):\n",
    "            print(f\"{i:>3}. {term}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1bee07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Label background (10 concepts) ===\n",
      "  1. aim\n",
      "  2. develop\n",
      "  3. cancer\n",
      "  4. common\n",
      "  5. physical\n",
      "  6. investigate\n",
      "  7. examine\n",
      "  8. potential\n",
      "  9. support\n",
      " 10. need\n",
      "\n",
      "=== Label conclusions (10 concepts) ===\n",
      "  1. provide\n",
      "  2. finding\n",
      "  3. suggest\n",
      "  4. demonstrate\n",
      "  5. need\n",
      "  6. safe\n",
      "  7. large\n",
      "  8. significant\n",
      "  9. effective\n",
      " 10. support\n",
      "\n",
      "=== Label methods (10 concepts) ===\n",
      "  1. randomize\n",
      "  2. receive\n",
      "  3. blind\n",
      "  4. group\n",
      "  5. assign\n",
      "  6. perform\n",
      "  7. measure\n",
      "  8. include\n",
      "  9. month\n",
      " 10. secondary\n",
      "\n",
      "=== Label objective (10 concepts) ===\n",
      "  1. aim\n",
      "  2. investigate\n",
      "  3. evaluate\n",
      "  4. examine\n",
      "  5. determine\n",
      "  6. safety\n",
      "  7. different\n",
      "  8. efficacy\n",
      "  9. objective\n",
      " 10. acute\n",
      "\n",
      "=== Label results (10 concepts) ===\n",
      "  1. p\n",
      "  2. group\n",
      "  3. significant\n",
      "  4. difference\n",
      "  5. score\n",
      "  6. mean\n",
      "  7. ratio\n",
      "  8. event\n",
      "  9. month\n",
      " 10. placebo\n"
     ]
    }
   ],
   "source": [
    "pretty_print_layer(layer_1_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07257749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>n_union_features</th>\n",
       "      <th>score</th>\n",
       "      <th>rel_gain</th>\n",
       "      <th>added_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.356584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'methods': ['randomize', 'receive', 'blind', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0.414120</td>\n",
       "      <td>0.161352</td>\n",
       "      <td>{'methods': ['perform', 'measure', 'include', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.430970</td>\n",
       "      <td>0.040688</td>\n",
       "      <td>{'methods': ['day', 'conduct', 'participant', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iter  n_union_features     score  rel_gain  \\\n",
       "0     1                23  0.356584  0.000000   \n",
       "1     2                42  0.414120  0.161352   \n",
       "2     3                64  0.430970  0.040688   \n",
       "\n",
       "                                         added_terms  \n",
       "0  {'methods': ['randomize', 'receive', 'blind', ...  \n",
       "1  {'methods': ['perform', 'measure', 'include', ...  \n",
       "2  {'methods': ['day', 'conduct', 'participant', ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29a040ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(layer_1_keywords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af76855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== methods (10 concepts) ===\n",
      "['randomize', 'receive', 'blind', 'group', 'assign', 'perform', 'measure', 'include', 'month', 'secondary']\n",
      "=== results (10 concepts) ===\n",
      "['p', 'group', 'significant', 'difference', 'score', 'mean', 'ratio', 'event', 'month', 'placebo']\n",
      "=== objective (10 concepts) ===\n",
      "['aim', 'investigate', 'evaluate', 'examine', 'determine', 'safety', 'different', 'efficacy', 'objective', 'acute']\n",
      "=== conclusions (10 concepts) ===\n",
      "['provide', 'finding', 'suggest', 'demonstrate', 'need', 'safe', 'large', 'significant', 'effective', 'support']\n",
      "=== background (10 concepts) ===\n",
      "['aim', 'develop', 'cancer', 'common', 'physical', 'investigate', 'examine', 'potential', 'support', 'need']\n"
     ]
    }
   ],
   "source": [
    "for label, keywords in layer_1_keywords.items():\n",
    "    print(f\"=== {label} ({len(keywords)} concepts) ===\")\n",
    "    print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1b2f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_des = CONFIG[\"class_descriptions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0dd9a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_for_label(label_name, \n",
    "                                             label_description, \n",
    "                                             keywords, \n",
    "                                             all_labels,\n",
    "                                             used_concepts_per_label,\n",
    "                                             n_keywords=5, \n",
    "                                             topic=\"medical\", \n",
    "                                             task_description=\"text classification with multi-hop reasoning\"):\n",
    "    \n",
    "    keyword_list_str = \", \".join(keywords)\n",
    "    all_labels_str = \", \".join(all_labels)\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are assisting in building a multi-layered reasoning system for {topic} {task_description}. \n",
    "This system performs concept abstraction to enhance explainability and classification performance.\n",
    "\n",
    "You are working on the **second concept layer** — abstracting surface-level keywords into **mid-level abstract concepts**.\n",
    "\n",
    "---\n",
    "\n",
    "### OBJECTIVE:\n",
    "\n",
    "Given:\n",
    "- A list of raw keywords related to a specific label.\n",
    "- The label’s name and description.\n",
    "- The list of **all possible labels** in the classification task.\n",
    "\n",
    "Your job:\n",
    "- Generate exactly {n_keywords} concise, meaningful mid-level concepts.\n",
    "- For each concept, return the list of 2–5 supporting keywords from the input list used to form this concept.\n",
    "\n",
    "Each concept must be:\n",
    "- More abstract than individual keywords\n",
    "- More specific than the label name\n",
    "- Useful in distinguishing this label from others\n",
    "- Expressed as a **short noun phrase**, not a sentence\n",
    "\n",
    "---\n",
    "\n",
    "### INPUTS:\n",
    "\n",
    "- Target Label: {label_name}\n",
    "- Label Description: {label_description}\n",
    "- All Labels: {all_labels_str}\n",
    "- Extracted Keywords: {keyword_list_str}\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### OUTPUT:\n",
    "\n",
    "Return a list of {n_keywords} JSON objects. Each object must contain:\n",
    "- \"concept\": <noun phrase>\n",
    "- \"supporting_keywords\": <list of relevant keywords from the input list>\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c18aaae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['methods', 'results', 'objective', 'conclusions', 'background']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4bd9b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_concepts = {label: layer_1_keywords[label] for label in class_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46bf0f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'methods': ['randomize',\n",
       "  'receive',\n",
       "  'blind',\n",
       "  'group',\n",
       "  'assign',\n",
       "  'perform',\n",
       "  'measure',\n",
       "  'include',\n",
       "  'month',\n",
       "  'secondary'],\n",
       " 'results': ['p',\n",
       "  'group',\n",
       "  'significant',\n",
       "  'difference',\n",
       "  'score',\n",
       "  'mean',\n",
       "  'ratio',\n",
       "  'event',\n",
       "  'month',\n",
       "  'placebo'],\n",
       " 'objective': ['aim',\n",
       "  'investigate',\n",
       "  'evaluate',\n",
       "  'examine',\n",
       "  'determine',\n",
       "  'safety',\n",
       "  'different',\n",
       "  'efficacy',\n",
       "  'objective',\n",
       "  'acute'],\n",
       " 'conclusions': ['provide',\n",
       "  'finding',\n",
       "  'suggest',\n",
       "  'demonstrate',\n",
       "  'need',\n",
       "  'safe',\n",
       "  'large',\n",
       "  'significant',\n",
       "  'effective',\n",
       "  'support'],\n",
       " 'background': ['aim',\n",
       "  'develop',\n",
       "  'cancer',\n",
       "  'common',\n",
       "  'physical',\n",
       "  'investigate',\n",
       "  'examine',\n",
       "  'potential',\n",
       "  'support',\n",
       "  'need']}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8576cc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_label = class_names[0]\n",
    "n_abstracts = len(layer_1_keywords[first_label]) // 2\n",
    "n_abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f51a8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_2_map = {}\n",
    "used_concepts_per_label = {}\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    prompt = generate_prompt_for_label(\n",
    "        label_name=class_names[i], \n",
    "        label_description=class_des[i], \n",
    "        keywords=layer_1_keywords[i], \n",
    "        all_labels=class_names,\n",
    "        used_concepts_per_label=used_concepts_per_label,\n",
    "        n_keywords=n_abstracts,\n",
    "        topic=\"stack overflow question quality\",\n",
    "        task_description=\"classify questions based on quality indicators like clarity, completeness, and relevance\"\n",
    "    )\n",
    "\n",
    "    res, e = gemini.call(\n",
    "      contents=[prompt],\n",
    "      output_struct={\n",
    "          \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"concept\": {\"type\": \"string\"},\n",
    "                    \"supporting_keywords\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\"type\": \"string\"},\n",
    "                        \"minItems\": 1\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"concept\", \"supporting_keywords\"]\n",
    "            }\n",
    "      }\n",
    "  )\n",
    "\n",
    "    layer_2_map[class_names[i]] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0db33e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'methods': [{'concept': 'general programming methods',\n",
       "   'supporting_keywords': ['functions', 'classes', 'methods', 'procedures']},\n",
       "  {'concept': 'algorithmic approaches',\n",
       "   'supporting_keywords': ['algorithms',\n",
       "    'strategies',\n",
       "    'techniques',\n",
       "    'approaches']},\n",
       "  {'concept': 'data structures and manipulation',\n",
       "   'supporting_keywords': ['data structures',\n",
       "    'arrays',\n",
       "    'lists',\n",
       "    'sorting',\n",
       "    'searching']},\n",
       "  {'concept': 'object-oriented programming',\n",
       "   'supporting_keywords': ['inheritance',\n",
       "    'polymorphism',\n",
       "    'encapsulation',\n",
       "    'abstraction']},\n",
       "  {'concept': 'functional programming concepts',\n",
       "   'supporting_keywords': ['higher-order functions',\n",
       "    'lambdas',\n",
       "    'recursion',\n",
       "    'immutability']}],\n",
       " 'results': [{'concept': 'Observed Outcomes',\n",
       "   'supporting_keywords': ['findings',\n",
       "    'observations',\n",
       "    'outcomes',\n",
       "    'discoveries']},\n",
       "  {'concept': 'Statistical Significance',\n",
       "   'supporting_keywords': ['significance',\n",
       "    'statistical results',\n",
       "    'p-values',\n",
       "    'confidence intervals']},\n",
       "  {'concept': 'Data Interpretation',\n",
       "   'supporting_keywords': ['interpretation',\n",
       "    'data analysis',\n",
       "    'evidence',\n",
       "    'trends']},\n",
       "  {'concept': 'Key Findings Summary',\n",
       "   'supporting_keywords': ['summary',\n",
       "    'key findings',\n",
       "    'main points',\n",
       "    'highlights']},\n",
       "  {'concept': 'Implications of Findings',\n",
       "   'supporting_keywords': ['implications',\n",
       "    'consequences',\n",
       "    'meaning',\n",
       "    'significance of findings']}],\n",
       " 'objective': [{'concept': 'study methodology',\n",
       "   'supporting_keywords': ['study design',\n",
       "    'experimental procedures',\n",
       "    'data collection methods']},\n",
       "  {'concept': 'participant characteristics',\n",
       "   'supporting_keywords': ['participant demographics',\n",
       "    'sample description',\n",
       "    'subject selection criteria']},\n",
       "  {'concept': 'analytical approach',\n",
       "   'supporting_keywords': ['statistical analysis',\n",
       "    'data interpretation techniques',\n",
       "    'research approach']},\n",
       "  {'concept': 'experimental setup',\n",
       "   'supporting_keywords': ['equipment used',\n",
       "    'laboratory conditions',\n",
       "    'treatment application']},\n",
       "  {'concept': 'research protocol',\n",
       "   'supporting_keywords': ['step-by-step procedures',\n",
       "    'experimental timeline',\n",
       "    'protocol adherence']}],\n",
       " 'conclusions': [{'concept': 'research aims',\n",
       "   'supporting_keywords': ['hypothesis', 'research question', 'purpose']},\n",
       "  {'concept': 'study outcomes',\n",
       "   'supporting_keywords': ['findings', 'implications', 'significance']},\n",
       "  {'concept': 'future directions',\n",
       "   'supporting_keywords': ['next steps',\n",
       "    'further research',\n",
       "    'recommendations']},\n",
       "  {'concept': 'main message',\n",
       "   'supporting_keywords': ['key takeaway', 'summary', 'takeaway']},\n",
       "  {'concept': 'overall goal',\n",
       "   'supporting_keywords': ['aim', 'objective', 'purpose of study']}],\n",
       " 'background': [{'concept': 'Research Findings',\n",
       "   'supporting_keywords': ['outcomes', 'findings', 'key results']},\n",
       "  {'concept': 'Statistical Data Presentation',\n",
       "   'supporting_keywords': ['statistical data', 'data presentation']},\n",
       "  {'concept': 'Observed Phenomena',\n",
       "   'supporting_keywords': ['observations', 'phenomena']},\n",
       "  {'concept': 'Experimental Outcomes',\n",
       "   'supporting_keywords': ['outcomes', 'experimental results']},\n",
       "  {'concept': 'Reported Results',\n",
       "   'supporting_keywords': ['results', 'reported data']}]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_2_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b85f1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_concepts = {\n",
    "    label: {\n",
    "        item[\"concept\"]: item[\"supporting_keywords\"]\n",
    "        for item in concepts\n",
    "    }\n",
    "    for label, concepts in layer_2_map.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8ef81ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'methods': {'general programming methods': ['functions',\n",
       "   'classes',\n",
       "   'methods',\n",
       "   'procedures'],\n",
       "  'algorithmic approaches': ['algorithms',\n",
       "   'strategies',\n",
       "   'techniques',\n",
       "   'approaches'],\n",
       "  'data structures and manipulation': ['data structures',\n",
       "   'arrays',\n",
       "   'lists',\n",
       "   'sorting',\n",
       "   'searching'],\n",
       "  'object-oriented programming': ['inheritance',\n",
       "   'polymorphism',\n",
       "   'encapsulation',\n",
       "   'abstraction'],\n",
       "  'functional programming concepts': ['higher-order functions',\n",
       "   'lambdas',\n",
       "   'recursion',\n",
       "   'immutability']},\n",
       " 'results': {'Observed Outcomes': ['findings',\n",
       "   'observations',\n",
       "   'outcomes',\n",
       "   'discoveries'],\n",
       "  'Statistical Significance': ['significance',\n",
       "   'statistical results',\n",
       "   'p-values',\n",
       "   'confidence intervals'],\n",
       "  'Data Interpretation': ['interpretation',\n",
       "   'data analysis',\n",
       "   'evidence',\n",
       "   'trends'],\n",
       "  'Key Findings Summary': ['summary',\n",
       "   'key findings',\n",
       "   'main points',\n",
       "   'highlights'],\n",
       "  'Implications of Findings': ['implications',\n",
       "   'consequences',\n",
       "   'meaning',\n",
       "   'significance of findings']},\n",
       " 'objective': {'study methodology': ['study design',\n",
       "   'experimental procedures',\n",
       "   'data collection methods'],\n",
       "  'participant characteristics': ['participant demographics',\n",
       "   'sample description',\n",
       "   'subject selection criteria'],\n",
       "  'analytical approach': ['statistical analysis',\n",
       "   'data interpretation techniques',\n",
       "   'research approach'],\n",
       "  'experimental setup': ['equipment used',\n",
       "   'laboratory conditions',\n",
       "   'treatment application'],\n",
       "  'research protocol': ['step-by-step procedures',\n",
       "   'experimental timeline',\n",
       "   'protocol adherence']},\n",
       " 'conclusions': {'research aims': ['hypothesis',\n",
       "   'research question',\n",
       "   'purpose'],\n",
       "  'study outcomes': ['findings', 'implications', 'significance'],\n",
       "  'future directions': ['next steps', 'further research', 'recommendations'],\n",
       "  'main message': ['key takeaway', 'summary', 'takeaway'],\n",
       "  'overall goal': ['aim', 'objective', 'purpose of study']},\n",
       " 'background': {'Research Findings': ['outcomes', 'findings', 'key results'],\n",
       "  'Statistical Data Presentation': ['statistical data', 'data presentation'],\n",
       "  'Observed Phenomena': ['observations', 'phenomena'],\n",
       "  'Experimental Outcomes': ['outcomes', 'experimental results'],\n",
       "  'Reported Results': ['results', 'reported data']}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d98e5609",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    \"keyword_concepts\": keyword_concepts,\n",
    "    \"abstract_concepts\": abstract_concepts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f08daf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_keys(data_dict, label_map):\n",
    "    return {label_map.get(str(k), str(k)): v for k, v in data_dict.items()}\n",
    "\n",
    "output_converted = {\n",
    "    \"keyword_concepts\": convert_label_keys(output[\"keyword_concepts\"], CONFIG[\"label_map\"]),\n",
    "    \"abstract_concepts\": convert_label_keys(output[\"abstract_concepts\"], CONFIG[\"label_map\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f95cad05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keyword_concepts': {'methods': ['randomize',\n",
       "   'receive',\n",
       "   'blind',\n",
       "   'group',\n",
       "   'assign',\n",
       "   'perform',\n",
       "   'measure',\n",
       "   'include',\n",
       "   'month',\n",
       "   'secondary'],\n",
       "  'results': ['p',\n",
       "   'group',\n",
       "   'significant',\n",
       "   'difference',\n",
       "   'score',\n",
       "   'mean',\n",
       "   'ratio',\n",
       "   'event',\n",
       "   'month',\n",
       "   'placebo'],\n",
       "  'objective': ['aim',\n",
       "   'investigate',\n",
       "   'evaluate',\n",
       "   'examine',\n",
       "   'determine',\n",
       "   'safety',\n",
       "   'different',\n",
       "   'efficacy',\n",
       "   'objective',\n",
       "   'acute'],\n",
       "  'conclusions': ['provide',\n",
       "   'finding',\n",
       "   'suggest',\n",
       "   'demonstrate',\n",
       "   'need',\n",
       "   'safe',\n",
       "   'large',\n",
       "   'significant',\n",
       "   'effective',\n",
       "   'support'],\n",
       "  'background': ['aim',\n",
       "   'develop',\n",
       "   'cancer',\n",
       "   'common',\n",
       "   'physical',\n",
       "   'investigate',\n",
       "   'examine',\n",
       "   'potential',\n",
       "   'support',\n",
       "   'need']},\n",
       " 'abstract_concepts': {'methods': {'general programming methods': ['functions',\n",
       "    'classes',\n",
       "    'methods',\n",
       "    'procedures'],\n",
       "   'algorithmic approaches': ['algorithms',\n",
       "    'strategies',\n",
       "    'techniques',\n",
       "    'approaches'],\n",
       "   'data structures and manipulation': ['data structures',\n",
       "    'arrays',\n",
       "    'lists',\n",
       "    'sorting',\n",
       "    'searching'],\n",
       "   'object-oriented programming': ['inheritance',\n",
       "    'polymorphism',\n",
       "    'encapsulation',\n",
       "    'abstraction'],\n",
       "   'functional programming concepts': ['higher-order functions',\n",
       "    'lambdas',\n",
       "    'recursion',\n",
       "    'immutability']},\n",
       "  'results': {'Observed Outcomes': ['findings',\n",
       "    'observations',\n",
       "    'outcomes',\n",
       "    'discoveries'],\n",
       "   'Statistical Significance': ['significance',\n",
       "    'statistical results',\n",
       "    'p-values',\n",
       "    'confidence intervals'],\n",
       "   'Data Interpretation': ['interpretation',\n",
       "    'data analysis',\n",
       "    'evidence',\n",
       "    'trends'],\n",
       "   'Key Findings Summary': ['summary',\n",
       "    'key findings',\n",
       "    'main points',\n",
       "    'highlights'],\n",
       "   'Implications of Findings': ['implications',\n",
       "    'consequences',\n",
       "    'meaning',\n",
       "    'significance of findings']},\n",
       "  'objective': {'study methodology': ['study design',\n",
       "    'experimental procedures',\n",
       "    'data collection methods'],\n",
       "   'participant characteristics': ['participant demographics',\n",
       "    'sample description',\n",
       "    'subject selection criteria'],\n",
       "   'analytical approach': ['statistical analysis',\n",
       "    'data interpretation techniques',\n",
       "    'research approach'],\n",
       "   'experimental setup': ['equipment used',\n",
       "    'laboratory conditions',\n",
       "    'treatment application'],\n",
       "   'research protocol': ['step-by-step procedures',\n",
       "    'experimental timeline',\n",
       "    'protocol adherence']},\n",
       "  'conclusions': {'research aims': ['hypothesis',\n",
       "    'research question',\n",
       "    'purpose'],\n",
       "   'study outcomes': ['findings', 'implications', 'significance'],\n",
       "   'future directions': ['next steps', 'further research', 'recommendations'],\n",
       "   'main message': ['key takeaway', 'summary', 'takeaway'],\n",
       "   'overall goal': ['aim', 'objective', 'purpose of study']},\n",
       "  'background': {'Research Findings': ['outcomes', 'findings', 'key results'],\n",
       "   'Statistical Data Presentation': ['statistical data', 'data presentation'],\n",
       "   'Observed Phenomena': ['observations', 'phenomena'],\n",
       "   'Experimental Outcomes': ['outcomes', 'experimental results'],\n",
       "   'Reported Results': ['results', 'reported data']}}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8aefffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"concepts_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_converted, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abab430",
   "metadata": {},
   "source": [
    "# Concepts Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf86738",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f32b03f",
   "metadata": {},
   "source": [
    "# Concepts Interpretable Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd68cd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
